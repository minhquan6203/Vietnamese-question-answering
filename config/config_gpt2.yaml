data:
  dataset_folder: data
  train_dataset: train.csv
  val_dataset: dev.csv
  test_dataset: test.csv
  use_id: False # nếu set là True thì có sử dụng thông tin id, ngược lại thì không

tokenizer:
  padding: max_length
  max_input_length: 512
  max_target_length: 64
  truncation: True

text_embedding:
  type: pretrained #có 3 loại, pretrained, tf_idf, count_vec
  add_new_token: False
  text_encoder: NlpHUST/gpt2-vietnamese
  freeze: False

generator_args:
  max_length: 64
  num_beams: 4
  length_penalty: 1.5
  no_repeat_ngram_size: 3
  early_stopping: True

model:
  type_model: gpt2

train:
  output_dir: checkpoint
  seed: 12345
  num_train_epochs: 100
  patience: 5
  learning_rate: 2.0e-5
  weight_decay: 0.0
  warmup_ratio: 0.0
  warmup_steps: 0
  metric_for_best_model: f1
  per_device_train_batch_size: 8
  per_device_valid_batch_size: 8

inference:
  test_dataset: /content/data/test.csv
  batch_size: 2048